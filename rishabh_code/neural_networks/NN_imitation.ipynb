{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input, Lambda, Reshape\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import limited_gpu_memory_session\n",
    "set_session(limited_gpu_memory_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('./')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights.hdf5')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_base.hdf5')\n",
    "EXPERIENCE_BUFFER_FILE = os.path.join(DATA_DIR, 'experience_buffer.p')\n",
    "MODEL_IMAGE = os.path.join(DATA_DIR, 'siamese_vgg16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "def dense_relu_bn_dropout(x, size, dropout, alpha = 0.1, reg = 0):\n",
    "    x = Dense(size, kernel_regularizer = l2(reg))(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def create_network(reg, dropout, alpha = 0.1):\n",
    "    inputs = Input(shape=(INPUT_SHAPE,))\n",
    "    x = dense_relu_bn_dropout(inputs, 16 , dropout, reg)\n",
    "    x = dense_relu_bn_dropout(x, 8, dropout, reg)\n",
    "    x = Dense(1)(x)\n",
    "    base_network = Model(inputs=inputs, outputs = x)\n",
    "    print(base_network.summary())\n",
    "    return base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 337\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  (None, 1)             385         input_5[0][0]                    \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)            (None, 1)             0           model_3[1][0]                    \n",
      "                                                                   model_3[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1)             0           subtract_2[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 385\n",
      "Trainable params: 337\n",
      "Non-trainable params: 48\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input, Lambda, Reshape\n",
    "\n",
    "INPUT_SHAPE = 8\n",
    "\n",
    "base_network = create_network(reg = 0.5, dropout = 0.5)\n",
    "input_a = Input(shape=(INPUT_SHAPE,))\n",
    "processed_a = base_network(input_a)\n",
    "input_b = Input(shape=(INPUT_SHAPE,))\n",
    "processed_b = base_network(input_b)\n",
    "distance = layers.Subtract()([processed_a, processed_b])\n",
    "out = Activation('sigmoid')(distance)\n",
    "siamese_net = Model([input_a, input_b], out)\n",
    "    \n",
    "siamese_net.save_weights(INIT_WEIGHTS)\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "MOVES = pickle.load(open(\"../moves_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in MOVES.iteritems():\n",
    "    MOVES[key] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,\n",
    "              patience=5, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=25,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = Nadam(lr=1e-3)\n",
    "siamese_net.compile(optimizer=nadam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "siamese_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience buffer loaded from /home/ubuntu/quackle/rishabh_code/neural_networks/experience_buffer.p\n",
      "Train: 2272842 Val: 94702\n"
     ]
    }
   ],
   "source": [
    "from utils import DataGenerator\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "load_from_file = os.path.exists(EXPERIENCE_BUFFER_FILE)\n",
    "save_to_file = not load_from_file\n",
    "datagen = DataGenerator(MOVES, batch_sz = BATCH_SIZE, load_from_file = load_from_file, \n",
    "                 save_to_file = save_to_file, file = EXPERIENCE_BUFFER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4434/4439 [============================>.] - ETA: 0s - loss: 0.7244 - acc: 0.4987Epoch 00000: val_acc improved from -inf to 0.26357, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "4439/4439 [==============================] - 39s - loss: 0.7244 - acc: 0.4987 - val_loss: 0.6929 - val_acc: 0.2636\n",
      "Epoch 2/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.4993Epoch 00001: val_acc did not improve\n",
      "4439/4439 [==============================] - 40s - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.2566\n",
      "Epoch 3/500\n",
      "4432/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.4994Epoch 00002: val_acc did not improve\n",
      "4439/4439 [==============================] - 40s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6933 - val_acc: 0.2405\n",
      "Epoch 4/500\n",
      "4437/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5013Epoch 00003: val_acc improved from 0.26357 to 0.27625, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "4439/4439 [==============================] - 39s - loss: 0.6932 - acc: 0.5013 - val_loss: 0.6932 - val_acc: 0.2763\n",
      "Epoch 5/500\n",
      "4438/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5003Epoch 00004: val_acc improved from 0.27625 to 0.33905, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "4439/4439 [==============================] - 39s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.3390\n",
      "Epoch 6/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5004Epoch 00005: val_acc did not improve\n",
      "4439/4439 [==============================] - 36s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.3175\n",
      "Epoch 7/500\n",
      "4434/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001Epoch 00006: val_acc improved from 0.33905 to 0.42301, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.4230\n",
      "Epoch 8/500\n",
      "4434/4439 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5001Epoch 00007: val_acc did not improve\n",
      "4439/4439 [==============================] - 39s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.3377\n",
      "Epoch 9/500\n",
      "4437/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001Epoch 00008: val_acc did not improve\n",
      "4439/4439 [==============================] - 36s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.3787\n",
      "Epoch 10/500\n",
      "4431/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5007Epoch 00009: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.3803\n",
      "Epoch 11/500\n",
      "4437/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001Epoch 00010: val_acc did not improve\n",
      "4439/4439 [==============================] - 39s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.2762\n",
      "Epoch 12/500\n",
      "4436/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5000Epoch 00011: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.3949\n",
      "Epoch 13/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4995\n",
      "Epoch 00012: reducing learning rate to 0.000500000023749.\n",
      "Epoch 00012: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.4995 - val_loss: 0.6931 - val_acc: 0.3558\n",
      "Epoch 14/500\n",
      "4436/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4993Epoch 00013: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.3507\n",
      "Epoch 15/500\n",
      "4435/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5002Epoch 00014: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.3323\n",
      "Epoch 16/500\n",
      "4432/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4999Epoch 00015: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.3413\n",
      "Epoch 17/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001Epoch 00016: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.3467\n",
      "Epoch 18/500\n",
      "4435/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4997\n",
      "Epoch 00017: reducing learning rate to 0.000250000011874.\n",
      "Epoch 00017: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.3574\n",
      "Epoch 19/500\n",
      "4438/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4996Epoch 00018: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.3949\n",
      "Epoch 20/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4992Epoch 00019: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.3601\n",
      "Epoch 21/500\n",
      "4436/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4990Epoch 00020: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.4991 - val_loss: 0.6931 - val_acc: 0.3757\n",
      "Epoch 22/500\n",
      "4435/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5002Epoch 00021: val_acc did not improve\n",
      "4439/4439 [==============================] - 35s - loss: 0.6931 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.3503\n",
      "Epoch 23/500\n",
      "4434/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5008\n",
      "Epoch 00022: reducing learning rate to 0.000125000005937.\n",
      "Epoch 00022: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.3476\n",
      "Epoch 24/500\n",
      "4435/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5000Epoch 00023: val_acc did not improve\n",
      "4439/4439 [==============================] - 39s - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.3554\n",
      "Epoch 25/500\n",
      "4435/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5003Epoch 00024: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.3296\n",
      "Epoch 26/500\n",
      "4438/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5002Epoch 00025: val_acc did not improve\n",
      "4439/4439 [==============================] - 39s - loss: 0.6931 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.3318\n",
      "Epoch 27/500\n",
      "4432/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5005Epoch 00026: val_acc did not improve\n",
      "4439/4439 [==============================] - 39s - loss: 0.6931 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.3606\n",
      "Epoch 28/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5010\n",
      "Epoch 00027: reducing learning rate to 6.25000029686e-05.\n",
      "Epoch 00027: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5010 - val_loss: 0.6932 - val_acc: 0.3592\n",
      "Epoch 29/500\n",
      "4431/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5008Epoch 00028: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.3542\n",
      "Epoch 30/500\n",
      "4438/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5008Epoch 00029: val_acc did not improve\n",
      "4439/4439 [==============================] - 38s - loss: 0.6931 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.3555\n",
      "Epoch 31/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5007Epoch 00030: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5007 - val_loss: 0.6932 - val_acc: 0.3607\n",
      "Epoch 32/500\n",
      "4438/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5016Epoch 00031: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.3559\n",
      "Epoch 33/500\n",
      "4433/4439 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5009\n",
      "Epoch 00032: reducing learning rate to 3.12500014843e-05.\n",
      "Epoch 00032: val_acc did not improve\n",
      "4439/4439 [==============================] - 37s - loss: 0.6931 - acc: 0.5009 - val_loss: 0.6932 - val_acc: 0.3556\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_PAIRS, NUM_VAL_PAIRS = datagen.get_num_pairs()\n",
    "STEPS_PER_EPOCH = NUM_TRAIN_PAIRS//BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_PAIRS//BATCH_SIZE\n",
    "history = siamese_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=500,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer, early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
