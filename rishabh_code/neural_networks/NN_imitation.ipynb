{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input, Lambda, Reshape\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('./')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights.hdf5')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_base.hdf5')\n",
    "EXPERIENCE_BUFFER_FILE = os.path.join(DATA_DIR, 'experience_buffer.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.initializers import VarianceScaling\n",
    "\n",
    "kernel_initializer = VarianceScaling(scale=0.001, mode='fan_avg', distribution='uniform', seed=42)\n",
    "\n",
    "def dense_relu_bn_dropout(x, size, dropout, activation='tanh', reg = 0):\n",
    "    x = Dense(size, kernel_regularizer = l2(reg), kernel_initializer=kernel_initializer)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def create_network(reg, dropout, activation = 'relu'):\n",
    "    inputs = Input(shape=(INPUT_SHAPE,), name=\"x\")\n",
    "    x = dense_relu_bn_dropout(inputs, size=8 , activation=activation,\n",
    "                              dropout=dropout, reg=reg)\n",
    "    x = Dense(1, kernel_initializer=kernel_initializer)(x)\n",
    "    base_network = Model(inputs=inputs, outputs = x)\n",
    "    print(base_network.summary())\n",
    "    return base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 8\n",
    "base_network = create_network(activation='selu', reg = 0, dropout = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WEIGHTS = base_network.get_weights()\n",
    "for i in xrange(len(BASE_WEIGHTS)):\n",
    "    if i == 0:\n",
    "        BASE_WEIGHTS[i][:2, 0] = 1\n",
    "    elif i == 2:\n",
    "        BASE_WEIGHTS[i][0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1.00000000e+00,   6.87097199e-03,   1.14376266e-02,\n",
       "           9.90638509e-03,  -9.31235030e-04,   5.07418253e-03,\n",
       "          -1.21603794e-02,  -1.49377976e-02],\n",
       "        [  1.00000000e+00,   8.64972919e-03,  -1.08753508e-02,\n",
       "           1.38396267e-02,   1.25453826e-02,   3.69531848e-03,\n",
       "          -1.92501731e-02,  -9.78878234e-03],\n",
       "        [  2.35248357e-04,  -5.36064617e-03,  -1.76283326e-02,\n",
       "           1.82869155e-02,   1.27184298e-02,  -3.30814533e-03,\n",
       "           3.93750705e-03,  -6.21277466e-03],\n",
       "        [  2.83125602e-03,  -1.02147805e-02,   6.76937588e-03,\n",
       "          -1.90814082e-02,  -1.85549743e-02,   1.78885218e-02,\n",
       "           5.20928390e-03,  -1.06005678e-02],\n",
       "        [  5.86896390e-03,   1.42149385e-02,  -9.50662699e-03,\n",
       "          -8.80788267e-03,  -1.36415288e-03,  -8.05000495e-03,\n",
       "          -1.12284468e-02,  -2.86217965e-03],\n",
       "        [  1.67792682e-02,  -3.19867395e-03,   8.32178630e-03,\n",
       "           2.56576203e-03,  -7.71657284e-03,   1.35459248e-02,\n",
       "          -1.81600638e-03,  -1.91971418e-02],\n",
       "        [ -1.58476513e-02,  -8.32168479e-03,   9.55596752e-03,\n",
       "           1.44553799e-02,  -3.28954495e-03,   1.65057052e-02,\n",
       "           2.64847092e-03,  -3.64232622e-03],\n",
       "        [  1.22314077e-02,   1.65733527e-02,  -9.81407892e-03,\n",
       "          -1.19479932e-03,  -2.56678835e-03,   1.33307260e-02,\n",
       "           8.80287774e-03,   4.08476405e-03]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ 1.        ],\n",
       "        [ 0.0091613 ],\n",
       "        [ 0.01525017],\n",
       "        [ 0.01320851],\n",
       "        [-0.00124165],\n",
       "        [ 0.00676558],\n",
       "        [-0.01621384],\n",
       "        [-0.01991706]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_network.set_weights(BASE_WEIGHTS)\n",
    "base_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_21 (Model)                 (None, 1)             81          input_15[0][0]                   \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)            (None, 1)             0           model_21[1][0]                   \n",
      "                                                                   model_21[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 1)             0           subtract_8[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input, Lambda, Reshape\n",
    "\n",
    "input_a = Input(shape=(INPUT_SHAPE,))\n",
    "processed_a = base_network(input_a)\n",
    "input_b = Input(shape=(INPUT_SHAPE,))\n",
    "processed_b = base_network(input_b)\n",
    "distance = layers.Subtract()([processed_a, processed_b])\n",
    "out = Activation('sigmoid')(distance)\n",
    "siamese_net = Model([input_a, input_b], out)\n",
    "siamese_net.save_weights(INIT_WEIGHTS)\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "MOVES = pickle.load(open(\"../moves_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,\n",
    "              patience=4, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=1e-3,\n",
    "                              patience=15,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience buffer generated\n",
      "Experience buffer saved to experience_buffer/experience_buffer_len4.p\n",
      "Train: 1464961 Val: 61041\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import DataGenerator\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "maxlen = 4\n",
    "EXPERIENCE_BUFFER_FILE = \"experience_buffer/experience_buffer_len{}.p\".format(maxlen) \n",
    "load_from_file = False #os.path.exists(EXPERIENCE_BUFFER_FILE)\n",
    "save_to_file = not load_from_file\n",
    "datagen = DataGenerator(MOVES, batch_sz = BATCH_SIZE, load_from_file = load_from_file, \n",
    "                 save_to_file = save_to_file, maxlen = maxlen, file = EXPERIENCE_BUFFER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = Nadam(lr=1e-3)\n",
    "siamese_net.compile(optimizer=nadam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "siamese_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_PAIRS, NUM_VAL_PAIRS = datagen.get_num_pairs()\n",
    "STEPS_PER_EPOCH = NUM_TRAIN_PAIRS//BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_PAIRS//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1425/1430 [============================>.] - ETA: 0s - loss: 1.2797 - acc: 0.6549Epoch 00000: val_acc improved from -inf to 0.75819, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 18s - loss: 1.2773 - acc: 0.6551 - val_loss: 0.5409 - val_acc: 0.7582\n",
      "Epoch 2/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5843 - acc: 0.7158Epoch 00001: val_acc improved from 0.75819 to 0.77028, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 25s - loss: 0.5844 - acc: 0.7158 - val_loss: 0.5315 - val_acc: 0.7703\n",
      "Epoch 3/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5836 - acc: 0.7157Epoch 00002: val_acc improved from 0.77028 to 0.77101, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 24s - loss: 0.5836 - acc: 0.7157 - val_loss: 0.5314 - val_acc: 0.7710\n",
      "Epoch 4/250\n",
      "1426/1430 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.7156Epoch 00003: val_acc did not improve\n",
      "1430/1430 [==============================] - 27s - loss: 0.5825 - acc: 0.7156 - val_loss: 0.5277 - val_acc: 0.7702\n",
      "Epoch 5/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.7155Epoch 00004: val_acc did not improve\n",
      "1430/1430 [==============================] - 24s - loss: 0.5824 - acc: 0.7155 - val_loss: 0.5292 - val_acc: 0.7694\n",
      "Epoch 6/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5818 - acc: 0.7153Epoch 00005: val_acc improved from 0.77101 to 0.77158, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 26s - loss: 0.5818 - acc: 0.7153 - val_loss: 0.5284 - val_acc: 0.7716\n",
      "Epoch 7/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.7148Epoch 00006: val_acc did not improve\n",
      "1430/1430 [==============================] - 25s - loss: 0.5816 - acc: 0.7148 - val_loss: 0.5295 - val_acc: 0.7693\n",
      "Epoch 8/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.7154Epoch 00007: val_acc did not improve\n",
      "1430/1430 [==============================] - 26s - loss: 0.5805 - acc: 0.7154 - val_loss: 0.5262 - val_acc: 0.7704\n",
      "Epoch 9/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.7165Epoch 00008: val_acc did not improve\n",
      "1430/1430 [==============================] - 24s - loss: 0.5789 - acc: 0.7165 - val_loss: 0.5271 - val_acc: 0.7688\n",
      "Epoch 10/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.7177- ETA: 0s - loss: 0.5Epoch 00009: val_acc did not improve\n",
      "1430/1430 [==============================] - 22s - loss: 0.5769 - acc: 0.7177 - val_loss: 0.5224 - val_acc: 0.7706\n",
      "Epoch 11/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.7183\n",
      "Epoch 00010: reducing learning rate to 0.000500000023749.\n",
      "Epoch 00010: val_acc improved from 0.77158 to 0.77161, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 24s - loss: 0.5764 - acc: 0.7183 - val_loss: 0.5214 - val_acc: 0.7716\n",
      "Epoch 12/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5759 - acc: 0.7189- ETA: 0s - loss: 0.5759 - acc: 0.71Epoch 00011: val_acc did not improve\n",
      "1430/1430 [==============================] - 27s - loss: 0.5759 - acc: 0.7188 - val_loss: 0.5228 - val_acc: 0.7713\n",
      "Epoch 13/250\n",
      "1426/1430 [============================>.] - ETA: 0s - loss: 0.5759 - acc: 0.7186-Epoch 00012: val_acc did not improve\n",
      "1430/1430 [==============================] - 24s - loss: 0.5759 - acc: 0.7186 - val_loss: 0.5216 - val_acc: 0.7713\n",
      "Epoch 14/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.7195Epoch 00013: val_acc did not improve\n",
      "1430/1430 [==============================] - 19s - loss: 0.5754 - acc: 0.7195 - val_loss: 0.5220 - val_acc: 0.7712\n",
      "Epoch 15/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.7189- ETA: 8s -\n",
      "Epoch 00014: reducing learning rate to 0.000250000011874.\n",
      "Epoch 00014: val_acc did not improve\n",
      "1430/1430 [==============================] - 24s - loss: 0.5754 - acc: 0.7189 - val_loss: 0.5231 - val_acc: 0.7712\n",
      "Epoch 16/250\n",
      "1424/1430 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.719 - ETA: 0s - loss: 0.5749 - acc: 0.7197Epoch 00015: val_acc did not improve\n",
      "1430/1430 [==============================] - 21s - loss: 0.5749 - acc: 0.7198 - val_loss: 0.5205 - val_acc: 0.7716\n",
      "Epoch 17/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5752 - acc: 0.7195Epoch 00016: val_acc did not improve\n",
      "1430/1430 [==============================] - 17s - loss: 0.5752 - acc: 0.7195 - val_loss: 0.5213 - val_acc: 0.7712\n",
      "Epoch 18/250\n",
      "1425/1430 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7197Epoch 00017: val_acc improved from 0.77161 to 0.77168, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 14s - loss: 0.5751 - acc: 0.7197 - val_loss: 0.5218 - val_acc: 0.7717\n",
      "Epoch 19/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7198Epoch 00018: val_acc improved from 0.77168 to 0.77211, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 13s - loss: 0.5750 - acc: 0.7198 - val_loss: 0.5211 - val_acc: 0.7721\n",
      "Epoch 20/250\n",
      "1424/1430 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.7203Epoch 00019: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5748 - acc: 0.7203 - val_loss: 0.5213 - val_acc: 0.7714\n",
      "Epoch 21/250\n",
      "1424/1430 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.7197Epoch 00020: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5750 - acc: 0.7196 - val_loss: 0.5216 - val_acc: 0.7709\n",
      "Epoch 22/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7197Epoch 00021: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5752 - acc: 0.7197 - val_loss: 0.5217 - val_acc: 0.7701\n",
      "Epoch 23/250\n",
      "1423/1430 [============================>.] - ETA: 0s - loss: 0.5750 - acc: 0.7199Epoch 00022: val_acc improved from 0.77211 to 0.77226, saving model to /home/ubuntu/quackle/rishabh_code/neural_networks/checkpointed_weights.hdf5\n",
      "1430/1430 [==============================] - 12s - loss: 0.5750 - acc: 0.7198 - val_loss: 0.5208 - val_acc: 0.7723\n",
      "Epoch 24/250\n",
      "1424/1430 [============================>.] - ETA: 0s - loss: 0.5753 - acc: 0.7198Epoch 00023: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5754 - acc: 0.7197 - val_loss: 0.5217 - val_acc: 0.7715\n",
      "Epoch 25/250\n",
      "1427/1430 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.7196Epoch 00024: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5748 - acc: 0.7196 - val_loss: 0.5214 - val_acc: 0.7716\n",
      "Epoch 26/250\n",
      "1424/1430 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7197Epoch 00025: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5751 - acc: 0.7196 - val_loss: 0.5218 - val_acc: 0.7705\n",
      "Epoch 27/250\n",
      "1426/1430 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7196Epoch 00026: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5751 - acc: 0.7196 - val_loss: 0.5211 - val_acc: 0.7714\n",
      "Epoch 28/250\n",
      "1423/1430 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.7199\n",
      "Epoch 00027: reducing learning rate to 0.000125000005937.\n",
      "Epoch 00027: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5747 - acc: 0.7199 - val_loss: 0.5215 - val_acc: 0.7705\n",
      "Epoch 29/250\n",
      "1425/1430 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.7202Epoch 00028: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 12s - loss: 0.5749 - acc: 0.7202 - val_loss: 0.5224 - val_acc: 0.7702\n",
      "Epoch 30/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.7211Epoch 00029: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5745 - acc: 0.7211 - val_loss: 0.5214 - val_acc: 0.7710\n",
      "Epoch 31/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.7205Epoch 00030: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5746 - acc: 0.7206 - val_loss: 0.5207 - val_acc: 0.7704\n",
      "Epoch 32/250\n",
      "1423/1430 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.7201\n",
      "Epoch 00031: reducing learning rate to 6.25000029686e-05.\n",
      "Epoch 00031: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5747 - acc: 0.7201 - val_loss: 0.5215 - val_acc: 0.7701\n",
      "Epoch 33/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.7204Epoch 00032: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5748 - acc: 0.7204 - val_loss: 0.5212 - val_acc: 0.7705\n",
      "Epoch 34/250\n",
      "1428/1430 [============================>.] - ETA: 0s - loss: 0.5743 - acc: 0.7205Epoch 00033: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5743 - acc: 0.7205 - val_loss: 0.5208 - val_acc: 0.7709\n",
      "Epoch 35/250\n",
      "1429/1430 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7204Epoch 00034: val_acc did not improve\n",
      "1430/1430 [==============================] - 12s - loss: 0.5746 - acc: 0.7204 - val_loss: 0.5213 - val_acc: 0.7707\n"
     ]
    }
   ],
   "source": [
    "# siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "history = siamese_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=250,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAHwCAYAAACG3a9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19343edfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(14)\n",
    "\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['acc'])\n",
    "ax2.plot(history.history['val_acc'])\n",
    "ax2.set_title('model acc')\n",
    "ax2.set_ylabel('acc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train_acc', 'val_acc'], loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base weights:\n",
      "Loss: 0.866059393765 Acc: 0.777433728352\n",
      "Checkpointed weights:\n",
      "Loss: 0.521243631092 Acc: 0.770315935715\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        print(\"Base weights:\")\n",
    "        siamese_net.set_weights(BASE_WEIGHTS)\n",
    "    else:\n",
    "        print(\"Checkpointed weights:\")\n",
    "        siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "    val = siamese_net.evaluate_generator(\n",
    "            datagen.next_train(),\n",
    "            steps=STEPS_PER_EPOCH)\n",
    "    print(\"Loss: {} Acc: {}\".format(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# siamese_net.set_weights(BASE_WEIGHTS)\n",
    "siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "SAVE_MODEL = \"keras_tensorflow\"\n",
    "model_to_save = siamese_net.layers[2]\n",
    "model_to_save.summary()\n",
    "model_to_save.save(SAVE_MODEL, overwrite='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  9.31617543e-02,   6.28616884e-02,   6.34780750e-02,\n",
       "           6.31450415e-02,  -7.23109469e-02,   6.20519184e-02,\n",
       "          -7.01870769e-02,  -7.26490691e-02],\n",
       "        [  1.00306980e-01,   2.71187127e-02,   2.63463594e-02,\n",
       "           2.60378812e-02,  -9.34500918e-02,   2.53457744e-02,\n",
       "          -9.40271765e-02,  -9.67363417e-02],\n",
       "        [  1.05681620e-03,   6.32985553e-04,   9.75474075e-04,\n",
       "           9.69368266e-04,   7.25866761e-04,   9.12884832e-04,\n",
       "           9.65720508e-04,   1.36871787e-03],\n",
       "        [ -2.28267466e-03,   3.03111970e-02,   3.38098556e-02,\n",
       "           3.12345773e-02,   3.72106805e-02,   2.91743632e-02,\n",
       "           4.13598046e-02,   4.13997732e-02],\n",
       "        [  8.82115774e-03,   4.54497635e-02,   5.27618490e-02,\n",
       "           5.05710617e-02,   5.59164844e-02,   4.85748723e-02,\n",
       "           4.80583198e-02,   4.81603220e-02],\n",
       "        [ -5.40936030e-02,   2.33633500e-02,   2.44849846e-02,\n",
       "           1.94505006e-02,   4.33787555e-02,   2.68147942e-02,\n",
       "           4.31087092e-02,   4.26213369e-02],\n",
       "        [ -6.53685182e-02,   3.83141674e-02,   2.75471173e-02,\n",
       "           2.43220814e-02,   1.17212012e-01,   2.73973122e-02,\n",
       "           1.09673887e-01,   1.19514063e-01],\n",
       "        [ -1.83215153e+00,  -7.66078889e-01,  -7.52192378e-01,\n",
       "          -7.33604968e-01,   1.37556481e+00,  -7.34389603e-01,\n",
       "           1.35249841e+00,   1.41206014e+00]], dtype=float32),\n",
       " array([-2.98186946, -1.93869126, -1.96590018, -1.98271632,  1.92447758,\n",
       "        -1.94092822,  1.91390634,  1.9932785 ], dtype=float32),\n",
       " array([[ 0.11559259],\n",
       "        [ 0.16389301],\n",
       "        [ 0.16318709],\n",
       "        [ 0.16391227],\n",
       "        [-0.19592273],\n",
       "        [ 0.16305858],\n",
       "        [-0.19423985],\n",
       "        [-0.18344527]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_save.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "status = os.system(\"python keras_to_tensorflow.py keras_tensorflow\")\n",
    "if status == 0:\n",
    "    print(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
