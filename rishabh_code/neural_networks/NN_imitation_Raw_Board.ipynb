{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input, Lambda, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('./')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights.hdf5')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_base.hdf5')\n",
    "EXPERIENCE_BUFFER_FILE = os.path.join(DATA_DIR, 'experience_buffer.p')\n",
    "INPUT_SHAPE = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.zeros((15, 15, 27*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe input features st are processed by a residual tower that consists of a single\\nconvolutional block followed by either 19 or 39 residual blocks\\n(1) A convolution of 256 filters of kernel size 3\\xc3\\x973 with stride 1\\n(2) Batch normalization18\\n(3) A rectifier nonlinearity\\nEach residual block applies the following modules sequentially to its input:\\n(1) A convolution of 256 filters of kernel size 3\\xc3\\x973 with stride 1\\n(2) Batch normalization\\n(3) A rectifier nonlinearity\\n(4) A convolution of 256 filters of kernel size 3\\xc3\\x973 with stride 1\\n(5) Batch normalization\\n(6) A skip connection that adds the input to the block\\n(7) A rectifier nonlinearity\\nThe output of the residual tower is passed into two separate \\xe2\\x80\\x98heads\\xe2\\x80\\x99 for\\ncomputing the policy and value. The policy head applies the following modules:\\n(1) A convolution of 2 filters of kernel size 1\\xc3\\x971 with stride 1\\n(2) Batch normalization\\n(3) A rectifier nonlinearity\\n(4) A fully connected linear layer that outputs a vector of size 192+ 1= 362,\\ncorresponding to logit probabilities for all intersections and the pass move\\nThe value head applies the following modules:\\n(1) A convolution of 1 filter of kernel size 1\\xc3\\x971 with stride 1\\n(2) Batch normalization\\n(3) A rectifier nonlinearity\\n(4) A fully connected linear layer to a hidden layer of size 256\\n(5) A rectifier nonlinearity\\n(6) A fully connected linear layer to a scalar\\n(7) A tanh nonlinearity outputting a scalar in the range [\\xe2\\x88\\x921, 1]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The input features st are processed by a residual tower that consists of a single\n",
    "convolutional block followed by either 19 or 39 residual blocks\n",
    "(1) A convolution of 256 filters of kernel size 3×3 with stride 1\n",
    "(2) Batch normalization18\n",
    "(3) A rectifier nonlinearity\n",
    "Each residual block applies the following modules sequentially to its input:\n",
    "(1) A convolution of 256 filters of kernel size 3×3 with stride 1\n",
    "(2) Batch normalization\n",
    "(3) A rectifier nonlinearity\n",
    "(4) A convolution of 256 filters of kernel size 3×3 with stride 1\n",
    "(5) Batch normalization\n",
    "(6) A skip connection that adds the input to the block\n",
    "(7) A rectifier nonlinearity\n",
    "The output of the residual tower is passed into two separate ‘heads’ for\n",
    "computing the policy and value. The policy head applies the following modules:\n",
    "(1) A convolution of 2 filters of kernel size 1×1 with stride 1\n",
    "(2) Batch normalization\n",
    "(3) A rectifier nonlinearity\n",
    "(4) A fully connected linear layer that outputs a vector of size 192+ 1= 362,\n",
    "corresponding to logit probabilities for all intersections and the pass move\n",
    "The value head applies the following modules:\n",
    "(1) A convolution of 1 filter of kernel size 1×1 with stride 1\n",
    "(2) Batch normalization\n",
    "(3) A rectifier nonlinearity\n",
    "(4) A fully connected linear layer to a hidden layer of size 256\n",
    "(5) A rectifier nonlinearity\n",
    "(6) A fully connected linear layer to a scalar\n",
    "(7) A tanh nonlinearity outputting a scalar in the range [−1, 1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 15, 15, 54)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 15, 15, 256)   124672      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 15, 15, 256)   1024        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 15, 15, 256)   0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 15, 15, 256)   590080      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 15, 15, 256)   1024        conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 15, 15, 256)   0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 15, 15, 256)   590080      activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 15, 15, 256)   1024        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 15, 15, 256)   0           batch_normalization_3[0][0]      \n",
      "                                                                   activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 15, 15, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 15, 15, 256)   590080      activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 15, 15, 256)   1024        conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 15, 15, 256)   0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 15, 15, 256)   590080      activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 15, 15, 256)   1024        conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 15, 15, 256)   0           batch_normalization_5[0][0]      \n",
      "                                                                   activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 15, 15, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 15, 15, 256)   590080      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 15, 15, 256)   1024        conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 15, 15, 256)   0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 15, 15, 256)   590080      activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 15, 15, 256)   1024        conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 15, 15, 256)   0           batch_normalization_7[0][0]      \n",
      "                                                                   activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 15, 15, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 15, 15, 256)   590080      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 15, 15, 256)   1024        conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 15, 15, 256)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 15, 15, 256)   590080      activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 15, 15, 256)   1024        conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 15, 15, 256)   0           batch_normalization_9[0][0]      \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 15, 15, 256)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 15, 15, 256)   590080      activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 15, 15, 256)   1024        conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 15, 15, 256)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 15, 15, 256)   590080      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 15, 15, 256)   1024        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 15, 15, 256)   0           batch_normalization_11[0][0]     \n",
      "                                                                   activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 15, 15, 256)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 15, 15, 2)     514         activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 15, 15, 2)     8           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 15, 15, 2)     0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 450)           0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           115456      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             257         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6,152,971\n",
      "Trainable params: 6,147,335\n",
      "Non-trainable params: 5,636\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Add\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "W_init = 'glorot_normal' #'glorot_uniform'\n",
    "b_init = 'zeros'\n",
    "W_dense_init = W_init\n",
    "\n",
    "def residual_block(input):\n",
    "    x = conv_block(input, )\n",
    "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, input])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input, padding=\"same\"):\n",
    "    x = Conv2D(256, (3, 3), padding=padding)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def final_block(input):\n",
    "    x = Conv2D(2, (1,1))(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    x = Dense(1, activation = 'linear')(x)\n",
    "    return x\n",
    "\n",
    "INPUT_SHAPE = (15, 15, 27*2)\n",
    "reg = 1e-2\n",
    "model_input = Input(shape=INPUT_SHAPE)\n",
    "x = conv_block(model_input)\n",
    "for _ in range(5):\n",
    "    x = residual_block(x)\n",
    "x = final_block(x)\n",
    "convnet = Model(inputs = model_input, outputs = x)\n",
    "print(convnet.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 15, 15, 54)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 15, 15, 54)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 1)             6152971     input_4[0][0]                    \n",
      "                                                                   input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)            (None, 1)             0           model_1[1][0]                    \n",
      "                                                                   model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 1)             0           subtract_1[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 6,152,971\n",
      "Trainable params: 6,147,335\n",
      "Non-trainable params: 5,636\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input, Lambda, Reshape\n",
    "base_network = convnet\n",
    "input_a = Input(shape=INPUT_SHAPE)\n",
    "processed_a = base_network(input_a)\n",
    "input_b = Input(shape=INPUT_SHAPE)\n",
    "processed_b = base_network(input_b)\n",
    "distance = layers.Subtract()([processed_a, processed_b])\n",
    "out = Activation('sigmoid')(distance)\n",
    "siamese_net = Model([input_a, input_b], out)\n",
    "siamese_net.save_weights(INIT_WEIGHTS)\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WEIGHTS = siamese_net.get_weights()\n",
    "# BASE_WEIGHTS[0][2] = 0.1\n",
    "# siamese_net.set_weights(BASE_WEIGHTS)\n",
    "# print(BASE_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "MOVES = pickle.load(open(\"../moves_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARDS = pickle.load(open(\"../boards_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convert_boards; reload(convert_boards)\n",
    "from convert_boards import convert_boards\n",
    "boards = convert_boards(BOARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = boards.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = boards[keys[0]]\n",
    "x3 = x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 27)\n",
      "(15, 15, 27)\n",
      "(15, 15, 54)\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(x3.shape)\n",
    "x4 = np.concatenate((x1,x3), axis = -1)\n",
    "print(x4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {k : [i[0] for i in v] for k, v in MOVES.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,\n",
    "              patience=2, verbose = 1, min_lr=1e-7)\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=1e-3,\n",
    "                              patience=15,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((649143, 15, 15, 54), (649143,))\n",
      "Train: 636160 Val: 12983\n"
     ]
    }
   ],
   "source": [
    "import utils_board; reload(utils_board)\n",
    "from utils_board import DataGeneratorTest\n",
    "\n",
    "# keys_small = keys[:100000]\n",
    "# board_small = {k : boards[k] for k in keys_small}\n",
    "# scores_small = {k: scores[k] for k in keys_small}\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EXPERIENCE_BUFFER_FILE = \"experience_buffer/test_scores.npz\" \n",
    "load_from_file = False #os.path.exists(EXPERIENCE_BUFFER_FILE)\n",
    "save_to_file = False\n",
    "datagen = DataGeneratorTest(boards, scores, batch_sz = BATCH_SIZE, load_from_file = load_from_file, \n",
    "                 save_to_file = save_to_file, file = EXPERIENCE_BUFFER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 636160\n",
    "NUM_VAL = 12983\n",
    "STEPS_PER_EPOCH = NUM_TRAIN//BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = Nadam(lr=1e-3)\n",
    "convnet.compile(optimizer=nadam, loss='mse', metrics=['accuracy'])\n",
    "# convnet.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "  78/1242 [>.............................] - ETA: 13546s - loss: 259.5495 - acc: 0.0340"
     ]
    }
   ],
   "source": [
    "# siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "history = convnet.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=250,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAHwCAYAAABkAbQdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83a029d0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(14)\n",
    "\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['acc'])\n",
    "ax2.plot(history.history['val_acc'])\n",
    "ax2.set_title('model acc')\n",
    "ax2.set_ylabel('acc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train_acc', 'val_acc'], loc='lower left')\n",
    "\n",
    "# plt.show()\n",
    "f.savefig('results_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base weights:\n",
      "Loss: 0.72213492367 Acc: 0.221307516549\n",
      "Checkpointed weights:\n",
      "Loss: 0.508487781731 Acc: 0.749232751861\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        print(\"Base weights:\")\n",
    "        siamese_net.set_weights(BASE_WEIGHTS)\n",
    "    else:\n",
    "        print(\"Checkpointed weights:\")\n",
    "        siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "    val = siamese_net.evaluate_generator(\n",
    "            datagen.next_train(),\n",
    "            steps=STEPS_PER_EPOCH)\n",
    "    print(\"Loss: {} Acc: {}\".format(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "x (InputLayer)                   (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 8)             96          x[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 8)             32          dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 8)             0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 8)             0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "leave_score (Dense)              (None, 1)             12          x[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 9)             0           dropout_1[0][0]                  \n",
      "                                                                   leave_score[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             10          concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 150\n",
      "Trainable params: 134\n",
      "Non-trainable params: 16\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# siamese_net.set_weights(BASE_WEIGHTS)\n",
    "siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "SAVE_MODEL = \"keras_tensorflow\"\n",
    "model_to_save = siamese_net.layers[2]\n",
    "model_to_save.summary()\n",
    "model_to_save.save(SAVE_MODEL, overwrite='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ -7.77183101e-03,  -7.80454790e-03,  -6.26714388e-03,\n",
       "           1.05741378e-02,   9.92069021e-03,   1.00576524e-02,\n",
       "           1.00338655e-02,   9.84100625e-03],\n",
       "        [ -3.08994926e-03,  -3.22992448e-03,  -3.34323151e-03,\n",
       "          -7.43953802e-04,  -1.23617181e-04,  -6.85771462e-04,\n",
       "          -1.16106495e-03,   4.50546213e-04],\n",
       "        [ -6.50702859e-05,  -3.72116192e-05,  -1.00510602e-04,\n",
       "           4.91706247e-04,   2.39021159e-04,   3.25150671e-04,\n",
       "           2.11599501e-04,   2.64863920e-04],\n",
       "        [  3.64084216e-03,   3.17690801e-03,   3.72944027e-03,\n",
       "          -2.64052255e-03,  -2.14369525e-03,  -2.05290248e-03,\n",
       "          -2.41004070e-03,  -3.28733644e-04],\n",
       "        [  5.01143339e-04,   2.51307758e-03,   1.02558802e-03,\n",
       "          -7.31383625e-04,  -2.07398625e-04,  -9.87060950e-04,\n",
       "           7.24000391e-04,  -2.46735901e-04],\n",
       "        [ -3.60509672e-04,   5.92598633e-04,   1.33060137e-04,\n",
       "           5.41063841e-04,   2.51443055e-03,   2.81472248e-03,\n",
       "           1.24730275e-03,   2.38386402e-03],\n",
       "        [  6.09066943e-03,   4.78552422e-03,   3.92192462e-03,\n",
       "          -5.11663966e-03,  -4.70469240e-03,  -5.79440268e-03,\n",
       "          -5.83471823e-03,  -6.46775169e-03],\n",
       "        [  4.94480040e-03,   4.24919883e-03,   5.34849195e-03,\n",
       "          -1.63270626e-03,  -1.03060063e-03,  -1.21415709e-03,\n",
       "          -1.76630437e-03,  -6.16876467e-04],\n",
       "        [  1.25268358e-03,   6.18262740e-04,   8.40459834e-04,\n",
       "          -8.93722870e-04,  -3.23647924e-04,  -4.94270178e-04,\n",
       "          -2.29029378e-04,   1.81113966e-04],\n",
       "        [ -2.22500204e-03,  -6.17182057e-04,  -1.32010225e-03,\n",
       "           3.58384545e-03,   3.49483336e-03,   3.10201524e-03,\n",
       "           1.84211414e-03,   3.37692699e-03],\n",
       "        [ -4.91561223e-05,   1.73730688e-04,  -2.65428062e-05,\n",
       "          -6.92643225e-04,  -1.49066141e-03,  -4.85387282e-04,\n",
       "          -1.20181288e-03,  -8.85878399e-04]], dtype=float32),\n",
       " array([ 0.11477631, -0.04603926,  0.01952974,  0.09903229,  0.08851285,\n",
       "         0.03428952,  0.03890285,  0.04388251], dtype=float32),\n",
       " array([ 2.05445385,  2.05470419,  2.04174447,  0.82982326,  0.84317511,\n",
       "         0.82705766,  0.83395851,  0.83087051], dtype=float32),\n",
       " array([-0.69163072, -0.69262892, -0.6868645 ,  0.24398804,  0.24289754,\n",
       "         0.23932554,  0.23858383,  0.24058814], dtype=float32),\n",
       " array([-0.18523601, -0.32841325, -0.24334984,  0.48261726,  0.45346248,\n",
       "         0.41306388,  0.4000493 ,  0.39613247], dtype=float32),\n",
       " array([ 0.0230977 ,  0.02122419,  0.01749499,  0.03804729,  0.03418278,\n",
       "         0.0316469 ,  0.03539398,  0.02945813], dtype=float32),\n",
       " array([[ 1.52241004],\n",
       "        [ 0.76997048],\n",
       "        [ 0.0127772 ],\n",
       "        [ 0.02219595],\n",
       "        [ 0.04551413],\n",
       "        [ 0.16031198],\n",
       "        [-0.40681913],\n",
       "        [ 0.38986382],\n",
       "        [ 0.10173739],\n",
       "        [-0.1006089 ],\n",
       "        [-0.10220176]], dtype=float32),\n",
       " array([-0.09826075], dtype=float32),\n",
       " array([[ 0.31731942],\n",
       "        [ 0.31695512],\n",
       "        [ 0.32054713],\n",
       "        [-0.41373327],\n",
       "        [-0.40444243],\n",
       "        [-0.40680808],\n",
       "        [-0.40710673],\n",
       "        [-0.41102311],\n",
       "        [ 0.25172827]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_save.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "status = os.system(\"python keras_to_tensorflow.py keras_tensorflow\")\n",
    "if status == 0:\n",
    "    print(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
